# can expect improvement to -160 reward in ~30-40k timesteps
pendulum-ddpg-1:
    env: Pendulum-v0
    run: DDPG
    trial_resources:
        cpu: 6
        gpu: 1
    stop:
        episode_reward_mean: -160
        time_total_s: 1200
    config:
        random_starts: False
        clip_rewards: False
        exploration_fraction: 0.4
        model:
            fcnet_hiddens: []
        #tf_session_args:
        #    device_count:
        #        CPU: 2
        #        GPU: 1
