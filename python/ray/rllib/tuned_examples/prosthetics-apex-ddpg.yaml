prosthetics-apex-ddpg:
    env: prosthetics
    run: APEX_DDPG
    stop:
        # episode_reward_mean: 2400
        time_total_s: 900
    checkpoint_freq: 50
    checkpoint_at_end: True
    local_dir: /gruntdata/app_data/jones.wz/rl/nips2018/
    restore: /gruntdata/app_data/jones.wz/rl/nips2018/ray/python/ray/rllib/20180916/checkpoint-450
    config:
        # problem setting
        clip_rewards: False
        horizon: 75
        gamma: 0.95

        # Misc
        timesteps_per_iteration: 5000
        num_workers: 85
        gpu: True
        min_iter_time_s: 30

        # Exploration
        schedule_max_timesteps: 1000000
        exploration_fraction: 0.1
        exploration_final_eps: 0.02
        noise_scale: 2.5
        exploration_theta: 0.15
        exploration_sigma: 0.3
        per_worker_exploration: True
        worker_side_prioritization: False

        # Model
        model:
            fcnet_hiddens: [256]
            fcnet_activation: relu
        actor_hiddens: [128]
        actor_hidden_activation: relu
        critic_hiddens: [128]
        critic_hidden_activation: relu
 
        # Optimization
        n_step: 1
        target_network_update_freq: 500000
        tau: 1.0
        use_huber: False
        grad_norm_clipping: 40.0
        train_batch_size: 256
        sample_batch_size: 50
        max_weight_sync_delay: 200
        learning_starts: 50000

        # Replay buffer
        buffer_size: 2000000
